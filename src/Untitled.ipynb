{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**insert the testing and training images in seperate folders and pass the images to below given variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir='C:/Users/rupa/anaconda3/envs/FinalProject_AutoML/sampleImages/covid/train_filtered/'\n",
    "test_dir='C:/Users/rupa/anaconda3/envs/FinalProject_AutoML/sampleImages/covid/test_filtered/'\n",
    "covidTrainingAuc=0\n",
    "covidTestingAuc=0\n",
    "pneumoniaTrainingAuc=0\n",
    "pneumoniaTetingAuc=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deducting Covid-19 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from keras.layers import Input, Lambda, Dense, Flatten , Dropout , MaxPool2D\n",
    "from keras.models import Model , Sequential\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "from distutils.file_util import copy_file\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from keras.callbacks import EarlyStopping ,ReduceLROnPlateau\n",
    "from IPython.display import Javascript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28 images belonging to 2 classes.\n",
      "Found 7 images belonging to 2 classes.\n",
      "Found 35 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "img_height = 64\n",
    "img_width = 64\n",
    "batch_size = 8\n",
    "train_datagen = ImageDataGenerator(validation_split=0.2) # set validation split\n",
    "\n",
    "test_datagen = ImageDataGenerator()\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    classes = ['normal','covid'],\n",
    "    subset='training') # set as training data\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_dir, # same directory as training data\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    classes = ['normal','covid'],\n",
    "    subset='validation')\n",
    "\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir, # same directory as training data\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    classes = ['normal','covid'],\n",
    "    shuffle=False,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_weights {0: 2.5, 1: 1.0}\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.densenet import DenseNet121\n",
    "from tensorflow.keras import layers, metrics\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from collections import Counter\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def get_model(res, verbose=0):\n",
    "    base_model = DenseNet121(input_shape=(res, res, 3),include_top=False,weights='imagenet',pooling='avg')\n",
    "    x = base_model.output\n",
    "    x = layers.Dense(128, activation=\"relu\")(x)\n",
    "    output = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-5),loss='binary_crossentropy',metrics=[metrics.AUC(name='auc')])\n",
    "    if verbose: print(model.summary())\n",
    "    return model\n",
    "\n",
    "def get_class_weights(train_gen):\n",
    "    counter = Counter(train_gen.classes)                          \n",
    "    max_val = float(max(counter.values()))       \n",
    "    class_weights = {class_id : max_val/num_images for class_id, num_images in counter.items()}           \n",
    "    print(f'class_weights {class_weights}')\n",
    "    return class_weights\n",
    "\n",
    "def train_model(train_gen, val_gen, model, class_weights, epochs):\n",
    "    es_cb = callbacks.EarlyStopping(monitor='val_loss',patience=2,min_delta=0.001)\n",
    "    lr_cb = callbacks.ReduceLROnPlateau(patience=1,min_delta=.05)\n",
    "\n",
    "    history = model.fit(\n",
    "        train_gen\n",
    "        ,epochs=epochs\n",
    "        ,validation_data=val_gen\n",
    "        ,callbacks=[es_cb, lr_cb]\n",
    "        ,class_weight=class_weights)\n",
    "    \n",
    "res = 64\n",
    "model_densenet121 = get_model(res, verbose=0)\n",
    "class_weights = get_class_weights(train_generator)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_gen):\n",
    "    y_pred_prob = model.predict(test_gen)\n",
    "    y_true = test_gen.classes\n",
    "    auc_score = roc_auc_score(y_true, y_pred_prob)\n",
    "    return auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4/4 [==============================] - 43s 948ms/step - loss: 0.9041 - auc: 0.4914\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 3s 810ms/step - loss: 0.8031 - auc: 0.6195\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 3s 904ms/step - loss: 0.5898 - auc: 0.7333\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 3s 782ms/step - loss: 0.6645 - auc: 0.6987\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 3s 783ms/step - loss: 0.5282 - auc: 0.9272\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 3s 804ms/step - loss: 0.5677 - auc: 0.8514\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 3s 786ms/step - loss: 0.5558 - auc: 0.7234\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 3s 774ms/step - loss: 0.4203 - auc: 0.9388\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 3s 821ms/step - loss: 0.4314 - auc: 0.9470\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 3s 764ms/step - loss: 0.2648 - auc: 0.9975\n"
     ]
    }
   ],
   "source": [
    "#train_model(train_generator, validation_generator, model_densenet121, class_weights, epochs=5)\n",
    "ex_model_densenet121 = model_densenet121.fit(train_generator,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "covidTrainingAuc=ex_model_densenet121.history['auc'][9]*100\n",
    "if covidTrainingAuc!=0:\n",
    "    covidTestingAuc=test_model(model_densenet121, test_generator)*100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deducting Pneumonia **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 35 images belonging to 2 classes.\n",
      "Found 35 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 8\n",
    "IMG_SIZE = 224\n",
    "train_image_generator = ImageDataGenerator(rescale=1/255.)\n",
    "test_image_generator = ImageDataGenerator(rescale=1/255.)\n",
    "train_gen = train_image_generator.flow_from_directory(batch_size = BATCH_SIZE,\n",
    "                                                directory= train_dir,\n",
    "                                                shuffle = True,\n",
    "                                                target_size = (IMG_SIZE, IMG_SIZE))\n",
    "test_gen = test_image_generator.flow_from_directory(batch_size = BATCH_SIZE,\n",
    "                                                directory= test_dir,\n",
    "                                                target_size = (IMG_SIZE, IMG_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 224, 224, 3)\n",
      "(8, 2)\n"
     ]
    }
   ],
   "source": [
    "for item in train_gen:\n",
    "    images,labels = item\n",
    "    print(images.shape)\n",
    "    print(labels.shape)\n",
    "    break\n",
    "resnet50v2 = tf.keras.applications.ResNet50V2(include_top = False, \n",
    "                                  weights='imagenet', \n",
    "                                  input_shape = (IMG_SIZE, IMG_SIZE, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50v2 (Functional)      (None, 7, 7, 2048)        23564800  \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 128)               12845184  \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 36,426,754\n",
      "Trainable params: 36,381,314\n",
      "Non-trainable params: 45,440\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_resNet50  = tf.keras.Sequential([\n",
    "        resnet50v2,\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model_resNet50.compile(loss='categorical_crossentropy', \n",
    "              metrics=[\n",
    "                  tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "                  tf.keras.metrics.Precision(name='precision'),\n",
    "                  tf.keras.metrics.Recall(name='recall'),\n",
    "              ], \n",
    "              optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-5))\n",
    "model_resNet50.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "5/5 [==============================] - 76s 5s/step - loss: 0.7720 - accuracy: 0.6705 - precision: 0.6770 - recall: 0.6514\n",
      "Epoch 2/5\n",
      "5/5 [==============================] - 28s 6s/step - loss: 0.4753 - accuracy: 0.6898 - precision: 0.6781 - recall: 0.6869\n",
      "Epoch 3/5\n",
      "5/5 [==============================] - 28s 5s/step - loss: 0.2461 - accuracy: 0.8173 - precision: 0.8236 - recall: 0.8101\n",
      "Epoch 4/5\n",
      "5/5 [==============================] - 27s 5s/step - loss: 0.2660 - accuracy: 0.8165 - precision: 0.7650 - recall: 0.9228\n",
      "Epoch 5/5\n",
      "5/5 [==============================] - 27s 5s/step - loss: 0.1017 - accuracy: 0.9699 - precision: 0.9753 - recall: 0.9651\n"
     ]
    }
   ],
   "source": [
    "history = model_resNet50.fit(train_gen, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 6s 820ms/step - loss: 0.5599 - accuracy: 0.7143 - precision: 0.6923 - recall: 0.7714\n"
     ]
    }
   ],
   "source": [
    "scores = model_resNet50.evaluate(test_gen)\n",
    "pneumoniaTrainingAuc=history.history['accuracy'][4]*100\n",
    "pneumoniaTetingAuc=scores[1]*100\n",
    "#print(\"\\n%s: %.2f%%\" % (\"Testing Accuracy:\", scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**deducting severity of the image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Accuracy of all images\n",
      "Covid training Accuracy: 99.37499761581421\n",
      "Covid testing Accuracy: 82.80000000000001\n",
      "Severity of the virus in \u001b[1m COVID-1638.jpg \u001b[0m X-Ray\n",
      "Geographic Extent (0-8): 0.0\n",
      "Opacity (0-8): 0.0\n",
      "Severity of the virus in \u001b[1m COVID-1650.jpg \u001b[0m X-Ray\n",
      "Geographic Extent (0-8): 0.0\n",
      "Opacity (0-8): 0.0\n",
      "Severity of the virus in \u001b[1m COVID-1653.jpg \u001b[0m X-Ray\n",
      "Geographic Extent (0-8): 3.8\n",
      "Opacity (0-8): 1.816\n",
      "Severity of the virus in \u001b[1m COVID-1699.jpg \u001b[0m X-Ray\n",
      "Geographic Extent (0-8): 4.824\n",
      "Opacity (0-8): 5.278\n",
      "Severity of the virus in \u001b[1m COVID-1723.jpg \u001b[0m X-Ray\n",
      "Geographic Extent (0-8): 3.433\n",
      "Opacity (0-8): 1.586\n",
      "Severity of the virus in \u001b[1m COVID-1731.jpg \u001b[0m X-Ray\n",
      "Geographic Extent (0-8): 0.9822\n",
      "Opacity (0-8): 0.0\n",
      "Severity of the virus in \u001b[1m COVID-1732.jpg \u001b[0m X-Ray\n",
      "Geographic Extent (0-8): 6.086\n",
      "Opacity (0-8): 4.55\n",
      "Severity of the virus in \u001b[1m COVID-1735.jpg \u001b[0m X-Ray\n",
      "Geographic Extent (0-8): 5.756\n",
      "Opacity (0-8): 4.32\n",
      "Severity of the virus in \u001b[1m COVID-1736.jpg \u001b[0m X-Ray\n",
      "Geographic Extent (0-8): 6.776\n",
      "Opacity (0-8): 3.749\n",
      "Severity of the virus in \u001b[1m COVID-1791.jpg \u001b[0m X-Ray\n",
      "Geographic Extent (0-8): 5.138\n",
      "Opacity (0-8): 4.279\n",
      "Severity of the virus in \u001b[1m COVID-2349.jpg \u001b[0m X-Ray\n",
      "Geographic Extent (0-8): 2.255\n",
      "Opacity (0-8): 3.166\n",
      "Severity of the virus in \u001b[1m COVID-2378.jpg \u001b[0m X-Ray\n",
      "Geographic Extent (0-8): 3.557\n",
      "Opacity (0-8): 2.303\n",
      "Severity of the virus in \u001b[1m COVID-2380.jpg \u001b[0m X-Ray\n",
      "Geographic Extent (0-8): 3.762\n",
      "Opacity (0-8): 2.189\n",
      "Severity of the virus in \u001b[1m COVID-2381.jpg \u001b[0m X-Ray\n",
      "Geographic Extent (0-8): 5.858\n",
      "Opacity (0-8): 2.277\n",
      "Severity of the virus in \u001b[1m COVID-2539.jpg \u001b[0m X-Ray\n",
      "Geographic Extent (0-8): 1.935\n",
      "Opacity (0-8): 2.394\n",
      "Severity of the virus in \u001b[1m COVID-2561.jpg \u001b[0m X-Ray\n",
      "Geographic Extent (0-8): 0.3308\n",
      "Opacity (0-8): 0.4836\n",
      "Severity of the virus in \u001b[1m COVID-2563.jpg \u001b[0m X-Ray\n",
      "Geographic Extent (0-8): 4.844\n",
      "Opacity (0-8): 4.933\n",
      "Severity of the virus in \u001b[1m COVID-2648.jpg \u001b[0m X-Ray\n",
      "Geographic Extent (0-8): 3.564\n",
      "Opacity (0-8): 2.64\n",
      "Severity of the virus in \u001b[1m COVID-2664.jpg \u001b[0m X-Ray\n",
      "Geographic Extent (0-8): 0.0\n",
      "Opacity (0-8): 1.041\n",
      "Severity of the virus in \u001b[1m COVID-2665.jpg \u001b[0m X-Ray\n",
      "Geographic Extent (0-8): 1.71\n",
      "Opacity (0-8): 0.0\n",
      "Severity of the virus in \u001b[1m COVID-2667.jpg \u001b[0m X-Ray\n",
      "Geographic Extent (0-8): 2.35\n",
      "Opacity (0-8): 0.0\n",
      "Severity of the virus in \u001b[1m COVID-2685.jpg \u001b[0m X-Ray\n",
      "Geographic Extent (0-8): 3.552\n",
      "Opacity (0-8): 3.076\n",
      "Severity of the virus in \u001b[1m COVID-2693.jpg \u001b[0m X-Ray\n",
      "Geographic Extent (0-8): 1.468\n",
      "Opacity (0-8): 1.096\n",
      "Severity of the virus in \u001b[1m COVID-2920.jpg \u001b[0m X-Ray\n",
      "Geographic Extent (0-8): 3.618\n",
      "Opacity (0-8): 2.666\n",
      "Severity of the virus in \u001b[1m COVID-2921.jpg \u001b[0m X-Ray\n",
      "Geographic Extent (0-8): 2.288\n",
      "Opacity (0-8): 0.0\n"
     ]
    }
   ],
   "source": [
    "if(covidTrainingAuc>pneumoniaTrainingAuc):\n",
    "    print(\"Combined Accuracy of all images\")\n",
    "    print(\"Covid training Accuracy:\",covidTrainingAuc)\n",
    "    print(\"Covid testing Accuracy:\",covidTestingAuc)\n",
    "    path_new = (os.listdir(train_dir+\"covid/\"))\n",
    "    #print(path_new)\n",
    "    for filename in path_new:\n",
    "        x = os.path.join(train_dir+\"covid/\", filename)\n",
    "        y = str(x.replace(\"/\",\"\\\\\"))\n",
    "        %run \"predict_severity\" $y\n",
    "else:\n",
    "    print(\"Combined Accuracy of all images\")\n",
    "    print(\"Pneumonia training Accuracy:\",pneumoniaTrainingAuc)\n",
    "    print(\"Pneumonia testing Accuracy:\",pneumoniaTetingAuc)\n",
    "    path_new = (os.listdir(train_dir+\"pneumonia/\"))\n",
    "    #print(path_new)\n",
    "    for filename in path_new:\n",
    "        x = os.path.join(train_dir+\"pneumonia/\", filename)\n",
    "        y = str(x.replace(\"/\",\"\\\\\"))\n",
    "        %run \"predict_severity\" $y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
